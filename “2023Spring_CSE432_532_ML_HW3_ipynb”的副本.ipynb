{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# This is the instructions for HW 3.\n",
        "\n",
        "# In this homework, you have Two programming Questions\n",
        "\n",
        "# The submission deadline is Feb 24th (next Friday) 23:59PM. Please submit the ipynb file to the canvas\n",
        "\n",
        "# NO Late submission\n",
        "\n",
        "The demos we used in the class can be found using the following link:\n",
        "\n",
        "https://colab.research.google.com/drive/1ONTJ_L_4CMcyJcXdCeljRntazdW1zjW6?usp=sharing\n",
        "\n",
        "https://colab.research.google.com/drive/1QI4v4_1bdeN5dJ_McV1Xn-RiavYvgymn?usp=sharing\n",
        "\n",
        "# ==============================================="
      ],
      "metadata": {
        "id": "858xvPa0cfoM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 1: KNN in image classification\n",
        "\n",
        "## Step1: Get to know the dataset [MNIST dataset](https://www.tensorflow.org/datasets/catalog/mnist) (Please click and read it before you run the following code)\n",
        "\n",
        "The following code downloads the MNIST dataset from the official website. Run this just once to get the \"mnist.pkl\" file. \n",
        "\n",
        "After you run this code, you can find the file in the \"Files\" option from the tool bar on the left \n",
        "\n",
        "<-"
      ],
      "metadata": {
        "id": "Sxcjr1VudWSb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "XntJALc5cacw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "495a92a8-bb10-43ae-e904-0ff745928267"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading train-images-idx3-ubyte.gz...\n",
            "Downloading t10k-images-idx3-ubyte.gz...\n",
            "Downloading train-labels-idx1-ubyte.gz...\n",
            "Downloading t10k-labels-idx1-ubyte.gz...\n",
            "Download complete.\n",
            "Save complete.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from urllib import request\n",
        "import gzip\n",
        "import pickle\n",
        "\n",
        "filename = [\n",
        "[\"training_images\",\"train-images-idx3-ubyte.gz\"],\n",
        "[\"test_images\",\"t10k-images-idx3-ubyte.gz\"],\n",
        "[\"training_labels\",\"train-labels-idx1-ubyte.gz\"],\n",
        "[\"test_labels\",\"t10k-labels-idx1-ubyte.gz\"]\n",
        "]\n",
        "\n",
        "def download_mnist():\n",
        "    base_url = \"http://yann.lecun.com/exdb/mnist/\"\n",
        "    for name in filename:\n",
        "        print(\"Downloading \"+name[1]+\"...\")\n",
        "        request.urlretrieve(base_url+name[1], name[1])\n",
        "    print(\"Download complete.\")\n",
        "\n",
        "def save_mnist():\n",
        "    mnist = {}\n",
        "    for name in filename[:2]:\n",
        "        with gzip.open(name[1], 'rb') as f:\n",
        "            mnist[name[0]] = np.frombuffer(f.read(), np.uint8, offset=16).reshape(-1,28*28)\n",
        "    for name in filename[-2:]:\n",
        "        with gzip.open(name[1], 'rb') as f:\n",
        "            mnist[name[0]] = np.frombuffer(f.read(), np.uint8, offset=8)\n",
        "    with open(\"mnist.pkl\", 'wb') as f:\n",
        "        pickle.dump(mnist,f)\n",
        "    print(\"Save complete.\")\n",
        "\n",
        "def init():\n",
        "    download_mnist()\n",
        "    save_mnist()\n",
        "#    print ((load()[0]).shape)\n",
        "def load():\n",
        "    with open(\"mnist.pkl\",'rb') as f:\n",
        "        mnist = pickle.load(f)\n",
        "    return mnist[\"training_images\"], mnist[\"training_labels\"], mnist[\"test_images\"], mnist[\"test_labels\"]\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    init()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## If you are interested in what the data looks like. You can run the following code to see."
      ],
      "metadata": {
        "id": "XHA2Nmurtau9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from matplotlib.colors import LogNorm\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "from urllib import request\n",
        "import gzip\n",
        "import math\n",
        "import pickle\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def loadB():\n",
        "    with open(\"mnist.pkl\",'rb') as f:\n",
        "        mnist = pickle.load(f)\n",
        "\n",
        "        training_images, training_labels, testing_images, testing_labels = mnist[\"training_images\"], mnist[\"training_labels\"], mnist[\"test_images\"], mnist[\"test_labels\"]\n",
        "        # Normalize the images\n",
        "        training_images.astype('float32')\n",
        "        testing_images.astype('float32')\n",
        "        training_images = training_images / 255\n",
        "        testing_images = testing_images / 255\n",
        "        return training_images, training_labels, testing_images, testing_labels\n",
        "\n",
        "\n",
        "TRimg,TRlab,TSimg,TSlab=loadB()\n",
        "print(len(TRimg),len(TRlab),len(TSimg),len(TSlab))\n",
        "print(len(TRimg[0]),len(TRlab),len(TSimg[0]),len(TSlab))\n",
        "\n",
        "showInd=66\n",
        "Column=np.reshape(TRimg[showInd], (784, 1))\n",
        "arr_2d = np.reshape(TRimg[showInd], (28, 28))\n",
        "arr_2dT=np.rot90(arr_2d)\n",
        "arr_2dTA=np.rot90(arr_2dT)\n",
        "Final=np.fliplr(arr_2dTA)\n",
        "#arr_2dTA=np.transpose(arr_2dT)\n",
        "#arr_2dTB=np.transpose(arr_2dTA)\n",
        "print(\"===========this is the original image===========\")\n",
        "plt.pcolor(Final)\n",
        "print(TRlab[showInd])\n",
        "plt.show()\n",
        "print(\"===========this is the vectorized image===========\")\n",
        "plt.pcolor(Column)\n",
        "plt.show()\n",
        "\n",
        "#pcm = plt.pcolormesh(arr_2d,cmap='RdBu_r')\n",
        "#plt.colorbar(pcm)\n",
        "#plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 600
        },
        "id": "qgVg6kzCtZxd",
        "outputId": "0cf06620-379a-4354-ef13-0ac78c545388"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "60000 60000 10000 10000\n",
            "784 60000 784 10000\n",
            "===========this is the original image===========\n",
            "6\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "===========this is the vectorized image===========\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## In the next part, please implement the KNN function for hand written digit recognition\n",
        "\n"
      ],
      "metadata": {
        "id": "Atv56Vm7dgnH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What is the format of the dataset:\n",
        "\n",
        "**x_train** : 60,000x784 numpy array that each row contains flattened version of training images. \n",
        "\n",
        "**y_train** : 1x60,000 numpy array that each component is true label of the  corresponding training images. \n",
        "\n",
        "**x_test** : 10,000x784 numpy array that each row contains flattened version of\n",
        "test images. Each vector of 784 is the vector for one image.\n",
        "\n",
        "**y_test** : 1x10,000 numpy array that each component is true label of the \n",
        "corresponding test images. "
      ],
      "metadata": {
        "id": "yRq3R-3Ice4V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Notice**:  Once  you  get  “mnist.pkl”,  you  don't  need  to  call  init()  anymore. \n",
        "Everything you need to do is to locate “mnist.pkl” \n",
        "in your working directory and  to call load(). Then you can load  the MNIST \n",
        "database in your code (given below) "
      ],
      "metadata": {
        "id": "42I7r1GMezTX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Notice**: Due to the high computational complexity of KNN, you do not need \n",
        "to  classify  all  10000  test  images.  Instead,  you  can  select  how  many  test \n",
        "images to classify in \n",
        "\n",
        "\"outputlabels=kNNClassify(x_test[0:20],x_train,y_train,10)\"\n",
        "\n",
        "The suggested configuration is 20 test images and K=10"
      ],
      "metadata": {
        "id": "ccLLytZbe9Ga"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note**: The code for data loading has been given. You can \n",
        "utilize them or write your own codes. Basically, you just need to modify the code bellow. You can choose the value of k (suggested value is 10). Also, \n",
        "choose L2 distance as the measurement metric. "
      ],
      "metadata": {
        "id": "DIuKSzPGfAef"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accuracy result and execution time should be printed out and you can directly use the code provided in the following"
      ],
      "metadata": {
        "id": "2JDBf3rpfUpK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 2 implement your KNN algorithm\n",
        "\n",
        "Now you need to implement the KNN algorithm below. Test the KNN algorithm for 20 test images. Calculate the processing overhead (time consumption) and the classification accuracy (code provided, the accuracy should be higher than 30%). "
      ],
      "metadata": {
        "id": "9_s1gFOl8UKM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import numpy as np  \n",
        "import operator  \n",
        "import time\n",
        "import pickle\n",
        "\n",
        "#load the data that you downloaded\n",
        "\n",
        "def load():\n",
        "    with open(\"mnist.pkl\",'rb') as f:\n",
        "        mnist = pickle.load(f)\n",
        "    return mnist[\"training_images\"], mnist[\"training_labels\"], mnist[\"test_images\"], mnist[\"test_labels\"]\n",
        "\n",
        "# classify using kNN  \n",
        "#x_train = np.load('../x_train.npy')\n",
        "#y_train = np.load('../y_train.npy')\n",
        "#x_test = np.load('../x_test.npy')\n",
        "#y_test = np.load('../y_test.npy')\n",
        "'''\n",
        "The meaning of each data\n",
        "x_train, training data\n",
        "y_train, corresponding label\n",
        "x_test,  testing data\n",
        "y_test. corresponding label\n",
        "'''\n",
        "x_train, y_train, x_test, y_test = load()\n",
        "print(x_train.shape) # should be (60000, 784) meaning 60000 images. each image has been converted into one vector.\n",
        "\n",
        "def most_frequent(List):\n",
        "    counter = 0\n",
        "    num = List[0]\n",
        "     \n",
        "    for i in List:\n",
        "        curr_frequency = List.count(i)\n",
        "        if(curr_frequency> counter):\n",
        "            counter = curr_frequency\n",
        "            num = i\n",
        " \n",
        "    return num\n",
        "\n",
        "def kNNClassify(newInput, dataSet, labels, k): \n",
        "    result=[]\n",
        "    ########################\n",
        "    # Add your code here #\n",
        "    ########################\n",
        "    \n",
        "    #step 1: calculate Euclidean distance (L2)\n",
        "    \n",
        "\n",
        "\n",
        "    #step 2: sort the distance \n",
        "\n",
        "\n",
        "\n",
        "    #step 3: the most common class will be returned \n",
        "    distanceTest = []\n",
        "    Klist = []\n",
        "    min = []\n",
        "    \n",
        "    for TE in range(newInput.shape[0]):\n",
        "      for TR in range(dataSet.shape[0]):\n",
        "        distanceTest.append(np.sqrt(np.sum((newInput[TE]-dataSet[TR])**2)))\n",
        "      #mindistance = np.asarray(distancelist)\n",
        "      min = np.argpartition(distanceTest,k)\n",
        "      #print(min)\n",
        "      for i in range(k):\n",
        "        Klist.append(labels[min[i]])\n",
        "        #print(labels[min[i]])\n",
        "      print(most_frequent(Klist))\n",
        "      result.append(most_frequent(Klist))\n",
        "      distanceTest = []\n",
        "      min = []\n",
        "      Klist = []\n",
        "        \n",
        "    ####################\n",
        "    # End of your code #\n",
        "    ####################\n",
        "    print(result)\n",
        "    return result\n",
        "\n",
        "\n",
        "#Calculate the processing overhead (time consumption) and the classification accuracy.\n",
        "start_time = time.time()\n",
        "outputlabels=kNNClassify(x_test[0:20],x_train,y_train,10) # your function\n",
        "result = y_test[0:20] - outputlabels\n",
        "result = (1 - np.count_nonzero(result)/len(outputlabels))\n",
        "print (\"---classification accuracy for knn on mnist: %s ---\" %result)\n",
        "print (\"---execution time: %s seconds ---\" % (time.time() - start_time))"
      ],
      "metadata": {
        "id": "Ij0t0dd3fGz_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f1f2dd8-b384-4ace-dce9-3c3d78e888d5"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 784)\n",
            "7\n",
            "1\n",
            "1\n",
            "0\n",
            "3\n",
            "1\n",
            "7\n",
            "7\n",
            "1\n",
            "1\n",
            "4\n",
            "4\n",
            "7\n",
            "1\n",
            "1\n",
            "1\n",
            "7\n",
            "1\n",
            "3\n",
            "4\n",
            "[7, 1, 1, 0, 3, 1, 7, 7, 1, 1, 4, 4, 7, 1, 1, 1, 7, 1, 3, 4]\n",
            "---classification accuracy for knn on mnist: 0.35 ---\n",
            "---execution time: 13.171547412872314 seconds ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 2 [K-Means](https://colab.research.google.com/drive/1QI4v4_1bdeN5dJ_McV1Xn-RiavYvgymn?usp=sharing) \n",
        "\n",
        "Comparing to the KNN, K-means is an unsupervised learning which does not require the label. In this question, you will directly divide the 10000 test images into 10 groups using K-means. This question has two challenging tasks that you need to solve:\n",
        "\n",
        "\n",
        "\n",
        "1.   Task 1: Implement the K-Means for image classification in MNIST dataset. (K=10) Check the different results when starting with different the centroids. For example, what would be the difference between selecting 10 centroids from each class and selecting 10 centroids from one class. (You do not need to calculate the accuracy)\n",
        "\n",
        "2.   Task 2: How to evaluate the performance. You need to carefully design the code to check the classification results, since in un-supervised learning, the clustering result does not include the classification results. For example, by using K-means, you know some data points belong to one cluster but you do not know which class it blongs to. For another example, after you apply the K-Means, you get 1000 images that are clustered into one group. However, some of them have the label of \"7\" and some of them have the label of \"8\". You do not know the class for this particular cluster. So, how to decide and how to ecaluate the classifcation accuracy is very challenge (groundtruth could be applied here). Please design an evaluation method to evaluate the clustering performance of using K-means in MNIST dataset.\n",
        "\n"
      ],
      "metadata": {
        "id": "3nwmkhPbfksl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Task 1 is required for all students.\n",
        "\n",
        "- Task 2 is only required for graduate student and is optional for undergraduate student. Any undergraduate student who finishes Task 2 will receive 10% bonus for this homework (not to the final grade) (should not exceed the full score)."
      ],
      "metadata": {
        "id": "yHXd3z_ofsog"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import numpy as np  \n",
        "import operator  \n",
        "import time\n",
        "import pickle\n",
        "import random\n",
        "\n",
        "#load the data that you downloaded\n",
        "\n",
        "def load():\n",
        "    with open(\"mnist.pkl\",'rb') as f:\n",
        "        mnist = pickle.load(f)\n",
        "    return mnist[\"training_images\"], mnist[\"training_labels\"], mnist[\"test_images\"], mnist[\"test_labels\"]\n",
        "\n",
        "# classify using kNN  \n",
        "#x_train = np.load('../x_train.npy')\n",
        "#y_train = np.load('../y_train.npy')\n",
        "#x_test = np.load('../x_test.npy')\n",
        "#y_test = np.load('../y_test.npy')\n",
        "'''\n",
        "x_train, training data\n",
        "y_train, corresponding label\n",
        "x_test,  testing data\n",
        "y_test. corresponding label\n",
        "'''\n",
        "x_train, y_train, x_test, y_test = load()\n",
        "print(x_train.shape)\n",
        "\n",
        "def KM(X_train, k):\n",
        "  index = random.sample(list(range(len(X_train))), k)\n",
        "  print(X_train.shape)\n",
        "  RepeatKM(X_train, index)\n",
        "\n",
        "def RepeatKM(X_train, Centroids):\n",
        "  NewClass=[]\n",
        "  # Classification for each data point\n",
        "  # Outer loop go through each data point\n",
        "  for One in X_train:\n",
        "    L2_Dis=[]\n",
        "    for Center in Centroids:\n",
        "      # for each datapoint, calculate the distance between this datapoint to \n",
        "      # each center.\n",
        "      L2_Dis.append(np.sqrt(np.sum((One-Center)**2)))\n",
        "    \n",
        "    NP_D=np.asarray(L2_Dis)\n",
        "    min_index = np.argmin(NP_D)\n",
        "    print(L2_Dis,min_index)\n",
        "    # find the new class for each datapoint based on the centroid of each class\n",
        "    NewClass.append(min_index)\n",
        "\n",
        "  Row,Col=Centroids.shape\n",
        "  #print(Row,Col)\n",
        "  # update the centroids based on the classification results\n",
        "  for i in range(Row):\n",
        "    TmpCent=np.zeros(Col)\n",
        "    count=0\n",
        "    for j in range(len(NewClass)):\n",
        "      if NewClass[j]==i:\n",
        "        #print(NewClass[j],i)\n",
        "        for k in range(Col):\n",
        "          TmpCent[k]=TmpCent[k]+X_train[j][k]\n",
        "        count=count+1\n",
        "    #print(TmpCent,\"====\",count)\n",
        "    for k in range(Col):\n",
        "      Centroids[i][k]=float(TmpCent[k]/count)\n",
        "    print(Centroids[i])\n",
        "  return Centroids\n",
        "\n",
        "X_train=np.array([[0,1,0],[0,1,1],[1,2,1],[1,2,0],[1,2,2],[2,2,2],[1,2, -1],[2,2,3],[-1, -1, -1],[0, -1, -2],[0, -1,1],[-1, -2,1]])\n",
        "Centroids=np.array([[0.0,1.0,0.0],[0,1.0,1.0],[1.0,2.0,1.0]])\n",
        "x,y=Centroids.shape\n",
        "print(x,y)\n",
        "# one iteratin of KMeans\n",
        "Centroids=RepeatKM(X_train,Centroids)\n",
        "#print(np.zeros(2))\n",
        "print(Centroids)\n",
        "#print(KM(x_train, 10))\n"
      ],
      "metadata": {
        "id": "j8tkZmTxGUUn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e8d4ad3-6e89-4798-ce5a-3fd5c96e7931"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 784)\n",
            "3 3\n",
            "[0.0, 1.0, 1.7320508075688772] 0\n",
            "[1.0, 0.0, 1.4142135623730951] 1\n",
            "[1.7320508075688772, 1.4142135623730951, 0.0] 2\n",
            "[1.4142135623730951, 1.7320508075688772, 1.0] 2\n",
            "[2.449489742783178, 1.7320508075688772, 1.0] 2\n",
            "[3.0, 2.449489742783178, 1.4142135623730951] 2\n",
            "[1.7320508075688772, 2.449489742783178, 2.0] 0\n",
            "[3.7416573867739413, 3.0, 2.23606797749979] 2\n",
            "[2.449489742783178, 3.0, 4.123105625617661] 0\n",
            "[2.8284271247461903, 3.605551275463989, 4.358898943540674] 0\n",
            "[2.23606797749979, 2.0, 3.1622776601683795] 1\n",
            "[3.3166247903554, 3.1622776601683795, 4.47213595499958] 1\n",
            "[ 0.    0.25 -1.  ]\n",
            "[-0.33333333 -0.66666667  1.        ]\n",
            "[1.4 2.  1.6]\n",
            "[[ 0.          0.25       -1.        ]\n",
            " [-0.33333333 -0.66666667  1.        ]\n",
            " [ 1.4         2.          1.6       ]]\n"
          ]
        }
      ]
    }
  ]
}